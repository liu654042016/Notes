<!--
 * @Author: liu kang
 * @Date: 2024-07-06 17:50:20
 * @LastEditors: fade
 * @LastEditTime: 2024-07-15 22:28:31
 * @FilePath: \Notes\me\参考.md
 * @Description: 
 * 
 * Copyright (c) 2024 by ${git_name_email}, All Rights Reserved. 
-->

# 网上扒的

## ai 编译器

### [1](https://testerhome.com/articles/29396?order_by=created_at&)

算子融合的原则是什么？哪些算子可以融合？
理解的编译器和解释器分别是什么
手写个不额外需要内存的方阵旋转吧
来说一说什么是 bank conflict，具体怎么规避的呢

### [2](https://www.nowcoder.com/feed/main/detail/d7a9ab02921045c68103794ea3d56749)

### [3](https://www.nowcoder.com/feed/main/detail/ae864e6615844ec2acf26398f6f33d4e)

#### tvm、tensorRT、cuda 展开讲讲。

#### compiler 前端针对 cpu、gpu、dla 的 partition 切图 pass 是怎么做的？

计算图分析：分析计算图以了解每个操作（operation）的特点，包括计算密集型、内存带宽需求、数据依赖等。
硬件特性分析：了解目标硬件的特性，包括计算能力、内存结构、并行度、数据传输带宽等。
划分策略设计：根据计算图和硬件特性，设计划分策略，决定哪些操作分配给哪些硬件执行。
图划分：实际执行图划分操作，将计算图划分成子图，每个子图对应一个硬件目标。
生成混合调度计划：为划分后的子图生成调度计划，确保在不同硬件之间高效协作。
优化和调整：根据具体的性能需求，对划分结果进行优化和调整。

* 计算图分析
  计算图分析是划分过程的基础，通常包括以下内容：

操作类型分析：确定每个操作是计算密集型还是内存密集型。
数据依赖分析：确定操作之间的数据依赖关系。
数据大小和形状分析：确定每个操作的输入和输出数据的大小和形状。

* 硬件特性分析
  不同硬件有不同的特性：

CPU：一般具有较高的灵活性和复杂的控制能力，但并行度较低。
GPU：具有高并行度和高内存带宽，适合处理大规模并行计算任务。
DLA（Deep Learning Accelerator）：专门设计用于深度学习计算，具有极高的计算效率，但灵活性较低。

* 划分策略设计
  划分策略设计是最关键的一步。常见的策略包括：

操作类型映射：将计算密集型操作分配给GPU，内存密集型操作分配给CPU。
数据依赖划分：确保数据依赖关系不会跨越硬件边界，或跨越边界的代价最小。
负载均衡：确保每个硬件的负载均衡，以避免某个硬件成为瓶颈。

* 图划分
  图划分是实际操作的执行过程，通常涉及以下步骤：
  标记操作：根据划分策略，对每个操作进行标记，指示其目标硬件。
  生成子图：根据标记，将计算图划分成子图，每个子图包含分配给同一硬件的操作。

```python
//tvm 自定义 pass 切分子图
from tvm.relay import ExprMutator, Function

class Annotator(ExprMutator):
    def visit_call(self, call):
        new_args = [self.visit(arg) for arg in call.args]
        new_call = relay.Call(call.op, new_args)
        # 根据某些条件标记子图
        if some_condition(new_call):
            return relay.annotation.on_device(new_call, relay.device.CUDA())
        return new_call

# 使用自定义的 Annotator 来标记子图
annotator = Annotator()
new_func = annotator.visit(f)

# 使用 PartitionGraph Pass 进行分割
with transform.PassContext(opt_level=3):
    mod = tvm.IRModule.from_expr(new_func)
    mod = relay_transform.PartitionGraph()(mod)

print(mod)

//复杂子图
import tvm
from tvm import relay
from tvm.relay import testing
from tvm.contrib import graph_runtime

# 创建一个简单的 Relay 计算图
data = relay.var("data", relay.TensorType((1, 3, 224, 224), "float32"))
weight = relay.var("weight", relay.TensorType((64, 3, 7, 7), "float32"))
conv = relay.nn.conv2d(data, weight, kernel_size=(7, 7), padding=(3, 3))
relu = relay.nn.relu(conv)
f = relay.Function([data, weight], relu)

# 使用自定义 Annotator 标记子图
class CustomAnnotator(ExprMutator):
    def visit_call(self, call):
        new_args = [self.visit(arg) for arg in call.args]
        new_call = relay.Call(call.op, new_args)
        if call.op.name == "nn.conv2d":
            return relay.annotation.on_device(new_call, relay.device.CUDA())
        return new_call

annotator = CustomAnnotator()
new_func = annotator.visit(f)

# 使用 PartitionGraph Pass 进行分割
with tvm.transform.PassContext(opt_level=3):
    mod = tvm.IRModule.from_expr(new_func)
    mod = relay.transform.PartitionGraph()(mod)

print(mod)


```

* 生成混合调度计划
  混合调度计划确保不同硬件之间的协作，包括：

数据传输计划：在硬件之间传输数据的计划，确保数据在需要的时间点到达需要的硬件。
同步机制：在不同硬件之间引入同步机制，以确保数据依赖关系的正确执行。

* 优化和调整
  最后，针对初始划分结果进行优化和调整，常见的优化包括：

数据传输优化：减少跨硬件的数据传输次数和传输量。
负载均衡调整：根据实际负载情况，对操作的分配进行调整，以平衡负载。
性能调优：基于性能分析结果，进一步调整划分策略和调度计划。

##### relay 到 tensorrt 和 py 的 api 图 codegen 是怎么做的？


#### 量化概念、掉点严重如何检查出敏感层？检查出来如何解决？（一般是切图或者fallback fp16，或者针对scale替换，针对掉点任务完善校准集等）

##### dla有不支持算子，比如const如何做？

#### 多模型并行推理runtime优化如何做的？（一系列实验找出来是同一core下linux的cfs调度问题）

#### c++智能指针、移动语义、虚函数等等八股。

8.手撕
并行课程2 hard、
合并数组区间 mid
图结构搜索+修改某个node语义 mid

### [4](https://blog.csdn.net/weixin_42868863/article/details/131149743)
TVM 中的调度器 (Scheduler) 是什么？请简要解释 TVM 调度器的作用和工作原理
在 TVM 中，调度器（Scheduler）是一个核心组件，用于定义和优化张量计算的执行方式。调度器允许用户指定高层次的优化策略，以提高计算效率。通过调度，用户可以控制计算任务如何被分割、分配和执行，以便充分利用底层硬件资源，如 CPU、GPU 等。

TVM 调度器的作用
分割计算任务：调度器可以将计算任务分割成更小的块，以便于并行执行。例如，可以将一个大矩阵乘法分割成多个小矩阵乘法。

数据布局变换：调度器可以调整数据在内存中的布局，以提高缓存利用率和内存访问效率。例如，可以将数据从行优先（row-major）布局转换为列优先（column-major）布局。

并行化：调度器可以将计算任务分配到多个线程或多个 GPU 上进行并行执行，以充分利用多核 CPU 或 GPU 的计算能力。

向量化：调度器可以将标量操作转换为向量操作，以利用 SIMD（Single Instruction, Multiple Data）指令集，提高计算效率。

内存优化：调度器可以调整计算和数据传输的顺序，以减少内存访问延迟。例如，可以在需要时将数据预取到缓存中，减少内存访问开销。

TVM 调度器的工作原理
TVM 调度器通过以下几个步骤来优化计算任务：

创建计算图：用户首先定义张量计算任务，生成计算图（computation graph）。这一步骤描述了计算任务的逻辑，但没有指定如何执行这些任务。

创建调度：用户为计算图创建调度（schedule）。调度指定了计算任务如何被分割、排列和执行。

应用调度优化：调度器应用一系列优化变换，将高层次的调度策略转化为低层次的代码生成策略。这些变换包括分块、向量化、线程绑定等。

代码生成：TVM 根据优化后的调度生成底层代码，可以是 CUDA、LLVM 等，用于在目标硬件上执行。

### [5](https://blog.finaltheory.me/research/MXNet-NNVM.html)
